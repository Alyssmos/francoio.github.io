--- 
title: "Cours Magistral 6"
output: html_document 
---

** **

#### Variance et covariance

Toutes les variables considérées sont de carré intégrable.

** **

##### Définitions

On définit la variance de $X$ par
$$
{\rm Var}[X] = \mathbb{E}[( X - \mathbb{E}[X])^2] \, , 
$$
et la covariance de $X$ et $Y$ par

$$
{\rm Cov}[X,Y] = \mathbb{E}[ (  X - \mathbb{E}[X] )(  Y - \mathbb{E}[Y] ) ] = \mathbb{E}[XY] -  \mathbb{E}[X] \mathbb{E}[Y]  \, . 
$$

** **

##### Variance d'une somme

Soient $X$ et $Y$ deux variables intégrables. Nous avons

$$
 {\rm Var}(X + Y)  =  {\rm Var}(X) +  {\rm Var}(Y) + 2{\rm Cov}[X,Y]
$$




##### [Indépendance](https://fr.wikipedia.org/wiki/Ind%C3%A9pendance_(probabilit%C3%A9s)) 

Si $X$ et $Y$ sont indépendantes, alors Cov$[X,Y] = 0$. 

** **

##### [Inégalité de Chebyshev](https://fr.wikipedia.org/wiki/Pafnouti_Tchebychev)  

Soit $\epsilon >0$. 
$$
{\rm P}( |X - {\rm E}[X]| > \epsilon ) \leq \frac{{\rm Var}[X]}{\epsilon^2}.
$$ 

** **

##### Loi des [grands nombres](https://fr.wikipedia.org/wiki/Loi_des_grands_nombres)  


Soient $X_1, X_2, ...$ sont des variables indépendantes et de même loi, alors
$$
{\rm P}( | \sum_i^n X_i/n - {\rm E}[X]| > \epsilon ) \to 0. 
$$


  

